{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44c8da24-08c6-4a30-abd5-6b126e7a8c0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Configuration - Data Paths\n",
    "BASE_PATH = \"/Volumes/workspace/default/file_store\"\n",
    "RAW_DATA_PATH = f\"{BASE_PATH}\"\n",
    "PROCESSED_DATA_PATH = f\"{BASE_PATH}/processed_data\"\n",
    "FEATURE_DATA_PATH = f\"{BASE_PATH}/feature_data\"\n",
    "MODEL_PATH = f\"{BASE_PATH}/models\"\n",
    "\n",
    "# Specific data files\n",
    "BENEFICIARY_FILE = f\"{RAW_DATA_PATH}/DE1_0_2008_Beneficiary_Summary_File_Sample_1.csv\"\n",
    "INPATIENT_CLAIMS_FILE = f\"{RAW_DATA_PATH}/DE1_0_2008_to_2010_Inpatient_Claims_Sample_1.csv\"\n",
    "\n",
    "# Delta Lake paths\n",
    "DELTA_BASE_PATH = f\"{BASE_PATH}/delta\"\n",
    "DELTA_BRONZE_PATH = f\"{DELTA_BASE_PATH}/bronze\"\n",
    "DELTA_SILVER_PATH = f\"{DELTA_BASE_PATH}/silver\"\n",
    "DELTA_GOLD_PATH = f\"{DELTA_BASE_PATH}/gold\"\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 2. Load Beneficiary Summary File\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Load beneficiary data\n",
    "beneficiary_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(BENEFICIARY_FILE)\n",
    "\n",
    "print(f\"Beneficiary records loaded: {beneficiary_df.count():,}\")\n",
    "print(f\"Number of columns: {len(beneficiary_df.columns)}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Display schema\n",
    "beneficiary_df.printSchema()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Show first few rows\n",
    "display(beneficiary_df.limit(10))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 3. Load Inpatient Claims File\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Load inpatient claims data\n",
    "inpatient_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(INPATIENT_CLAIMS_FILE)\n",
    "\n",
    "print(f\"Inpatient claims loaded: {inpatient_df.count():,}\")\n",
    "print(f\"Number of columns: {len(inpatient_df.columns)}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Display schema\n",
    "inpatient_df.printSchema()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Show first few rows\n",
    "display(inpatient_df.limit(10))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 4. Initial Data Quality Assessment\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Check missing values in beneficiary data\n",
    "print(\"=== Beneficiary Data - Missing Values ===\")\n",
    "beneficiary_missing = beneficiary_df.select([\n",
    "    (count(when(col(c).isNull(), c)) / count(lit(1))).alias(c) \n",
    "    for c in beneficiary_df.columns\n",
    "])\n",
    "display(beneficiary_missing)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Check missing values in inpatient data\n",
    "print(\"=== Inpatient Claims - Missing Values ===\")\n",
    "inpatient_missing = inpatient_df.select([\n",
    "    (count(when(col(c).isNull(), c)) / count(lit(1))).alias(c) \n",
    "    for c in inpatient_df.columns[:20]  # First 20 columns\n",
    "])\n",
    "display(inpatient_missing)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 5. Save to Delta Lake - Bronze Layer\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Create bronze layer directory if needed\n",
    "print(f\"Saving to Bronze layer: {DELTA_BRONZE_PATH}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Save beneficiary data to Delta format\n",
    "beneficiary_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(f\"{DELTA_BRONZE_PATH}/beneficiary\")\n",
    "\n",
    "print(\"✓ Beneficiary data saved to Delta Bronze layer\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Save inpatient claims to Delta format\n",
    "inpatient_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(f\"{DELTA_BRONZE_PATH}/inpatient_claims\")\n",
    "\n",
    "print(\"✓ Inpatient claims saved to Delta Bronze layer\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 6. Verify Delta Tables\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Read back from Delta to verify\n",
    "beneficiary_delta = spark.read.format(\"delta\").load(f\"{DELTA_BRONZE_PATH}/beneficiary\")\n",
    "inpatient_delta = spark.read.format(\"delta\").load(f\"{DELTA_BRONZE_PATH}/inpatient_claims\")\n",
    "\n",
    "print(f\"✓ Beneficiary Delta table: {beneficiary_delta.count():,} records\")\n",
    "print(f\"✓ Inpatient Delta table: {inpatient_delta.count():,} records\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Summary\n",
    "# MAGIC \n",
    "# MAGIC Data successfully ingested and stored in Delta Lake Bronze layer:\n",
    "# MAGIC - Beneficiary Summary: Patient demographics and conditions\n",
    "# MAGIC - Inpatient Claims: Hospital admissions and diagnoses\n",
    "# MAGIC \n",
    "# MAGIC Next step: Data Processing & EDA (02_data_processing)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingest_cms_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
